{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pickle\n",
    "import lightgbm as lgb\n",
    "import emoji\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from scipy.sparse import hstack, csr_matrix, vstack\n",
    "import numpy as np\n",
    "analyzer_emoji = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tfidf model...\n"
     ]
    }
   ],
   "source": [
    "print('Loading tfidf model...')\n",
    "tfidf = pickle.load(open(\"./vectorizer.pk\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model sentiment to predict...\n"
     ]
    }
   ],
   "source": [
    "print('Loading model sentiment to predict...')\n",
    "sentiment_model = lgb.Booster(model_file='./model_gbm_sentiment.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils extract emoji sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_emojis(str):\n",
    "    return [c for c in str if c in emoji.UNICODE_EMOJI]\n",
    "def sentiment_emojis(sentence):\n",
    "    emojis = extract_emojis(sentence)\n",
    "    result = [0,0,0,0]\n",
    "    if len(emojis) == 0:\n",
    "        return result\n",
    "    for icon in emojis:\n",
    "        sen_dict = analyzer_emoji.polarity_scores(icon)\n",
    "        sen = [sen_dict['neg'],sen_dict['neu'],sen_dict['pos'],sen_dict['compound']]\n",
    "        result = [result[i] + sen[i] for i in range(4)]\n",
    "    return [result[i] / len(emojis) for i in range(4)]\n",
    "def sentiment_emojis_row(row):\n",
    "    comment = row['comment']\n",
    "    sen_comment = sentiment_emojis(comment)\n",
    "    \n",
    "    row['emoji_neg'] = sen_comment[0]\n",
    "    row['emoji_neu'] = sen_comment[1]\n",
    "    row['emoji_pos'] = sen_comment[2]\n",
    "    row['emoji_compound'] = sen_comment[3]\n",
    "    \n",
    "    return row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_input(input_str):\n",
    "    if len(input_str) == 0:\n",
    "        input_str = ' '\n",
    "    return input_str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get statistic feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_statistic_feature(input_str): \n",
    "    # Add num words of comment as feature\n",
    "    num_words = len(input_str.split())\n",
    "    # Add num words unique of comment as feature\n",
    "    num_unique_words = len(set(w for w in input_str.split()))\n",
    "    # Add num words unique per num words of comment as feature\n",
    "    words_vs_unique = num_unique_words / num_words * 100\n",
    "    # Add emojis features\n",
    "    emoji_neg, emoji_neu, emoji_pos, emoji_compound = sentiment_emojis(input_str)\n",
    "    return np.array([num_words, num_unique_words, words_vs_unique, emoji_neg, emoji_neu, emoji_pos, emoji_compound])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TfIdf vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2vec(input_str):\n",
    "    return tfidf.transform([input_str])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get sentence features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2features(input_str):\n",
    "    return hstack([sent2vec(input_str), csr_matrix(get_statistic_feature(input_str))]).tocsr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infer sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_input = [\n",
    "    'ðŸ˜€ tá»‘t quÃ¡',\n",
    "    'tháº¥y khÃ´ng Ä‘Æ°á»£c',\n",
    "    'quÃ¡ tá»‡',\n",
    "    'táº¡m á»•n'\n",
    "]\n",
    "result = [sentiment_model.predict(sent2features(sen)) for sen in list_input]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=)) 0.05 ðŸ˜€ tá»‘t quÃ¡\n",
      "=(( 0.96 tháº¥y khÃ´ng Ä‘Æ°á»£c\n",
      "=(( 0.97 quÃ¡ tá»‡\n",
      "=)) 0.26 táº¡m á»•n\n"
     ]
    }
   ],
   "source": [
    "for str_input, sentiment in zip(list_input, result):\n",
    "    print('=))' if sentiment < 0.5 else '=((', \"%.2f\" % sentiment, str_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
